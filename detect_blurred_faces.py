#This script retrieves all the face-blurred datasets(from radius 1 to radius 15),
#and run the face detection model on each of them
#It will generate a report for each dataset, saying how many faces it detects and how long does it take.
#In this case, is will generate 15 reports
#It only works for the data generated by 'blurfaces_generatedata.py'

#Parameters:
#	imagedir: the directory containing all 15 folders
#	annotationdir: the keypoint annotation of COCO dataset 2017
#	outputdir: the directory to store those reports
#	upsample: non-negative integers. The higher the value, the smaller faces can be detected.

from pycocotools.coco import COCO
from PIL import Image, ImageFilter
import argparse

import json, time

import face_recognition

parser = argparse.ArgumentParser(description='Face detector and blurer')
parser.add_argument('--imagedir', type=str, default='./COCODatasets/')
parser.add_argument('--annotationdir', type=str, default='./COCODatasets/annotations/person_keypoints_val2017.json')
parser.add_argument('--outputdir', type=str, default='./COCODatasets/')
parser.add_argument('--upsample', type=int, default=2)

args = parser.parse_args()
image_dirs = []
for i in range(1,16):
	image_dirs.append(args.imagedir+'/face_blurred_upsample_2_radius_%s/' % str(i))
annotation_dir = args.annotationdir

cocoGt = COCO(annotation_dir)
catIds = cocoGt.getCatIds(catNms=['person'])
keys = cocoGt.getImgIds(catIds=catIds)
i=1
for image_dir in image_dirs:
	start_time = time.time()
	total_face_detected = 0
	print('Running...')
	for key in keys:
		image_name = (12-len(str(key)))*'0' + str(key) + '.jpg'
		image = face_recognition.load_image_file(image_dir + image_name)
		face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=args.upsample, model="cnn")
		total_face_detected += len(face_locations)

	write_json = args.outputdir + 'time_report_upsample_%s_radius_%s.json' % (args.upsample, str(i))
	fp = open(write_json, 'w')
	total_time = time.time()-start_time
	json.dump('The total time is: ' + str(total_time) + '.\n' + 'The total face detected: ' + str(total_face_detected), fp)
	print('Finished!')
	i+=1

# image = face_recognition.load_image_file("./COCODatasets/val2017/000000002299.jpg")
# face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=3, model="cnn")

# for face_location in face_locations:

#     # Print the location of each face in this image
#     top, right, bottom, left = face_location
#     print("A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}".format(top, left, bottom, right))
#     print(face_location)
#     # You can access the actual face itself like this:
#     face_image = image[top:bottom, left:right]
#     pil_image = Image.fromarray(face_image)
    